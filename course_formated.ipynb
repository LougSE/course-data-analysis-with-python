{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Python - IBM Course Notes\n",
    "\n",
    "## Course Overview\n",
    "This notebook contains comprehensive notes from the IBM Data Analysis with Python course on Coursera. It covers fundamental concepts and practical implementations of data analysis using Python's popular libraries.\n",
    "\n",
    "**Course Link:** [Data Analysis with Python on Coursera](https://www.coursera.org/learn/data-analysis-with-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Structure\n",
    "\n",
    "| Module | Topic | Duration |\n",
    "|--------|--------|----------|\n",
    "| 1 | Importing Data Sets | 1 hour |\n",
    "| 2 | Data Wrangling | 1 hour |\n",
    "| 3 | Exploratory Data Analysis | 2 hours |\n",
    "| 4 | Model Development | 2 hours |\n",
    "| 5 | Model Evaluation and Refinement | 2 hours |\n",
    "| 6 | Final Assignment | 4 hours |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: Importing Data Sets\n",
    "\n",
    "### Python Libraries for Data Analysis\n",
    "\n",
    "#### Scientific Computing Libraries\n",
    "- **NumPy**: Fundamental package for scientific computing with Python\n",
    "  - Arrays and matrices\n",
    "  - Mathematical functions\n",
    "  - Random number capabilities\n",
    "\n",
    "- **Pandas**: Data manipulation and analysis library\n",
    "  - DataFrame and Series objects\n",
    "  - Data importing and exporting\n",
    "  - Data alignment and integration\n",
    "\n",
    "- **SciPy**: Advanced computing library\n",
    "  - Scientific and technical computing\n",
    "  - Optimization and linear algebra\n",
    "  - Signal and image processing\n",
    "\n",
    "#### Visualization Libraries\n",
    "- **Matplotlib**: Basic plotting library\n",
    "  - Create static, animated, and interactive visualizations\n",
    "  - Extensive customization options\n",
    "\n",
    "- **Seaborn**: Statistical data visualization\n",
    "  - Built on top of Matplotlib\n",
    "  - Higher-level interface for statistical graphics\n",
    "\n",
    "- **Plotly**: Interactive visualization library\n",
    "  - Web-based plotting\n",
    "  - Interactive features\n",
    "  - Support for various chart types\n",
    "\n",
    "#### Machine Learning Libraries\n",
    "- **Scikit-learn**: Machine learning library\n",
    "  - Classification, regression, clustering\n",
    "  - Model selection and preprocessing\n",
    "\n",
    "- **StatsModels**: Statistical modeling\n",
    "  - Estimation of statistical models\n",
    "  - Statistical tests\n",
    "  - Statistical data exploration\n",
    "\n",
    "- **TensorFlow**: Deep learning framework\n",
    "  - Neural networks\n",
    "  - Deep learning models\n",
    "  - GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np  # for numerical operations\n",
    "import pandas as pd  # for data manipulation\n",
    "import matplotlib.pyplot as plt  # for visualization\n",
    "import seaborn as sns  # for statistical visualizations\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Importing Techniques\n",
    "\n",
    "#### Supported File Formats\n",
    "- CSV (.csv)\n",
    "- JSON (.json)\n",
    "- Excel (.xlsx, .xls)\n",
    "- Text files (.txt)\n",
    "- HDF5 (.h5, .hdf5)\n",
    "- SQL databases\n",
    "- Web APIs\n",
    "\n",
    "#### File Path Types\n",
    "1. Local files: `/path/to/file/data.csv`\n",
    "2. URLs: `https://example.com/data.csv`\n",
    "3. Database connections\n",
    "\n",
    "#### Common Import Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Import Examples\n",
    "\n",
    "# Basic CSV import\n",
    "df_basic = pd.read_csv('data.csv')\n",
    "\n",
    "# CSV with specific options\n",
    "df_advanced = pd.read_csv('data.csv',\n",
    "                         header=0,  # use first row as headers\n",
    "                         index_col=0,  # use first column as index\n",
    "                         parse_dates=['date_column'],  # parse date columns\n",
    "                         na_values=['NA', '?']  # custom NA values\n",
    "                        )\n",
    "\n",
    "# CSV without headers\n",
    "df_no_header = pd.read_csv('data.csv',\n",
    "                          header=None,\n",
    "                          names=['col1', 'col2', 'col3']  # custom column names\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration Methods\n",
    "\n",
    "#### Basic DataFrame Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we have a DataFrame 'df'\n",
    "\n",
    "# View first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()\n",
    "\n",
    "# View last few rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "df.tail()\n",
    "\n",
    "# Get DataFrame info\n",
    "print(\"\\nDataFrame information:\")\n",
    "df.info()\n",
    "\n",
    "# Get statistical summary\n",
    "print(\"\\nStatistical summary:\")\n",
    "df.describe()\n",
    "\n",
    "# Get statistical summary for all columns including non-numeric\n",
    "print(\"\\nComplete statistical summary:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "\n",
    "#### Strategies for Missing Data\n",
    "\n",
    "1. **Investigation**\n",
    "   - Check with data source\n",
    "   - Understand why data is missing\n",
    "   - Determine if missing pattern is random\n",
    "\n",
    "2. **Removal Options**\n",
    "   - Drop entire variables (columns)\n",
    "   - Drop specific observations (rows)\n",
    "   - Consider impact on sample size\n",
    "\n",
    "3. **Replacement Options**\n",
    "   - Mean/median imputation\n",
    "   - Mode imputation for categorical data\n",
    "   - Predictive imputation\n",
    "   - Forward/backward fill\n",
    "\n",
    "4. **Keep as Missing**\n",
    "   - Use algorithms that handle missing values\n",
    "   - Create missing value indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data Handling Examples\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing values per column:\")\n",
    "df.isnull().sum()\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Drop rows with missing values in specific columns\n",
    "df_cleaned_subset = df.dropna(subset=['important_column'])\n",
    "\n",
    "# Fill missing values with mean\n",
    "df_filled = df.fillna(df.mean())\n",
    "\n",
    "# Fill missing values with different strategies per column\n",
    "df_filled_custom = df.fillna({\n",
    "    'numeric_column': df['numeric_column'].mean(),\n",
    "    'categorical_column': 'unknown',\n",
    "    'datetime_column': df['datetime_column'].ffill()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Connectivity\n",
    "\n",
    "#### SQL Database Connection Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using SQLAlchemy (recommended approach)\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def connect_to_database(database_url):\n",
    "    \"\"\"\n",
    "    Create a database connection using SQLAlchemy.\n",
    "    \n",
    "    Parameters:\n",
    "    database_url (str): Database connection URL\n",
    "    \n",
    "    Returns:\n",
    "    engine: SQLAlchemy engine object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(database_url)\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def query_database(engine, query):\n",
    "    \"\"\"\n",
    "    Execute SQL query and return results as DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    engine: SQLAlchemy engine object\n",
    "    query (str): SQL query to execute\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Query results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_sql(query, engine)\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Export Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export examples\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv('exported_data.csv', index=False)\n",
    "\n",
    "# Export to Excel\n",
    "df.to_excel('exported_data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Export to JSON\n",
    "df.to_json('exported_data.json')\n",
    "\n",
    "# Export to SQL database\n",
    "df.to_sql('table_name', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Hands-on Labs\n",
    "1. [Importing Data Sets Lab 1](/labs/1_DA0101EN-Review-Introduction.ipynb)\n",
    "2. [Importing Data Sets Lab 2](/labs/2_Practice_data_loading.ipynb)\n",
    "3. [Data Wrangling Lab](/labs/3_DA0101EN-Review-Data-Wrangling.ipynb)\n",
    "\n",
    "### Further Reading\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "- [Real Python - Working with CSV Files](https://realpython.com/python-csv/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}